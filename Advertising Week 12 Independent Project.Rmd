---
title: "Week 12 Independent Project"
author: "Wilkister Mbaka"
date: "2022-07-15"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Advertising - Supervised Learning

## Defining the Question

**Specifying the Question**

Perform exploratory data analysis on the provided dataset and identify which individuals are 
most likely to click on her ads.

**Defining the metrics of success**

To perform univariate and bivariate data analysis and based on that, provide recommendations 
and on which individuals are most likely to click on her ads.

**Understanding the context**

A Kenyan entrepreneur has created an online cryptography course and would want to advertise 
it on her blog. She currently targets audiences originating from various countries. In the past, 
she ran ads to advertise a related course on the same blog and collected data in the process. 
She would now like to employ your services as a Data Science Consultant to help her identify 
which individuals are most likely to click on her ads.

**Experimental design taken**

1) Load the dataset
2) Clean the dataset.
3) perform Exploratory data analysis

## Reading The Data

``` {r}
#installing packages
library(data.table)
library(ggplot2)

#
#Loading the dataset
advert <- fread("http://bit.ly/IPAdvertisingData")
```

## Checking The Data
```{r}
#Previewing the first 6 rows
head(advert)
```
```{r}
#Previewing the last 6 rows
tail(advert)
```


```{r}
# Dimensionanity of the data
dim(advert)
```
There are 1000 rows and 10 columns
``` {r}
#Checking the datatypes
str(advert)

# The dataset has integer, number, character and datetime datatype
```

## Tidying The Dataset

``` {r}
#Finding the total number of missing values in each column
colSums(is.na(advert))
```
There are no missing values in the dataset

``` {r}
#Finding duplicated entries within the dataset
duplicated_rows <- advert[duplicated(advert),]
#Printing out the duplicated entries
duplicated_rows
```
There are no duplicates in the datset

**Checking for outliers**

``` {r}
#Checking for outliers using boxplot
library(dplyr)
data_num2 <- select_if(advert, is.numeric)             
data_num2 
boxplot(data_num2)
#We notice that outliers are only available in the Area income column, but since they represent 
#income different areas, we fail to drop them
```

## Exploratory Data Analysis

### Univariate Analysis 

**Numerical variables**
**Measures of Central Tendency**

**Mean**
``` {r}
#Finding the mean of the numerical columns
advert_mean1 <- mean(advert$`Daily Time Spent on Site`)
advert_mean2 <- mean(advert$Age)
advert_mean3 <- mean(advert$`Area Income`)
advert_mean4 <- mean(advert$`Daily Internet Usage`)
#Printing out the results for daily time spent on site
advert_mean1
#Printing results for Age
advert_mean2
#Printing the results for Area income
advert_mean3
#Printing results for daily internet usage
advert_mean4
#
```
**Median**
``` {r}
#Finding the Median of the numerical columns
advert_median1 <- median(advert$`Daily Time Spent on Site`)
advert_median2 <- median(advert$Age)
advert_median3 <- median(advert$`Area Income`)
advert_median4 <- median(advert$`Daily Internet Usage`)
#Printing out the results for daily time spent on site
advert_median1
#Printing results for Age
advert_median2
#Printing the results for Area income
advert_median3
#Printing results for daily internet usage
advert_median4
```

**Mode**
``` {r}
#Creating a function for finding mode
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}
#Calculating the mode of each column
advert_mode1 <- getmode(advert$`Daily Time Spent on Site`)
advert_mode2 <- getmode(advert$Age)
advert_mode3 <- getmode(advert$`Area Income`)
advert_mode4 <- getmode(advert$`Daily Internet Usage`)

#Printing out the results for daily time spent on site
advert_mode1
#Printing results for Age
advert_mode2
#Printing the results for Area income
advert_mode3
#Printing results for daily internet usage
advert_mode4
```

**Measures of Dispersion** 

**Maximum**
``` {r}
#Finding the maximum values in each cloumn
advert_max1 <- max(advert$`Daily Time Spent on Site`)
advert_max2 <- max(advert$Age)
advert_max3 <- max(advert$`Area Income`)
advert_max4 <- max(advert$`Daily Internet Usage`)

#Printing out the results for daily time spent on site
advert_max1
#Printing results for Age
advert_max2
#Printing the results for Area income
advert_max3
#Printing results for daily internet usage
advert_max4
```

**Minimum**
``` {r}
#Finding the minimum values in each column
advert_min1 <- min(advert$`Daily Time Spent on Site`)
advert_min2 <- min(advert$Age)
advert_min3 <- min(advert$`Area Income`)
advert_min4 <- min(advert$`Daily Internet Usage`)

#Printing out the results for daily time spent on site
advert_min1
#Printing results for Age
advert_min2
#Printing the results for Area income
advert_min3
#Printing results for daily internet usage
advert_min4
```

**Quantiles**
``` {r}
#Finding the quantiles in each cloumn
advert_quan1 <- quantile(advert$`Daily Time Spent on Site`)
advert_quan2 <- quantile(advert$Age)
advert_quan3 <- quantile(advert$`Area Income`)
advert_quan4 <- quantile(advert$`Daily Internet Usage`)
#Printing out the results for daily time spent on site
advert_quan1
#Printing results for Age
advert_quan2
#Printing the results for Area income
advert_quan3
#Printing results for daily internet usage
advert_quan4
```

**Variance**
``` {r}
#Finding the variance in each cloumn
advert_var1 <- var(advert$`Daily Time Spent on Site`)
advert_var2 <- var(advert$Age)
advert_var3 <- var(advert$`Area Income`)
advert_var4 <- var(advert$`Daily Internet Usage`)
#Printing out the results for daily time spent on site
advert_var1
#Printing results for Age
advert_var2
#Printing the results for Area income
advert_var3
#Printing results for daily internet usage
advert_var4
```

**Standard Deviation**
``` {r}
#Finding the standard deviation in each cloumn
advert_sd1 <- sd(advert$`Daily Time Spent on Site`)
advert_sd2 <- sd(advert$Age)
advert_sd3 <- sd(advert$`Area Income`)
advert_sd4 <- sd(advert$`Daily Internet Usage`)
#Printing out the results for daily time spent on site
advert_sd1
#Printing results for Age
advert_sd2
#Printing the results for Area income
advert_sd3
#Printing results for daily internet usage
advert_sd4
```

**Skeweness**
``` {r}
#importing the necessary packages
library(moments)
#Finding the skewness in each cloumn
advert_sk1 <- skewness(advert$`Daily Time Spent on Site`)
advert_sk2 <- skewness(advert$Age)
advert_sk3 <- skewness(advert$`Area Income`)
advert_sk4 <- skewness(advert$`Daily Internet Usage`)

#Printing out the results for daily time spent on site
#negative value which interprets that majority of the data are greater than the mean which 
#can also be interpreted that most data are concetrated on the right side of the tail.
advert_sk1
#Printing results for Age
#From the results below we can note that Age column has a positive skewness meaning majority of 
#the data are less than the mean
advert_sk2
#Printing the results for Area income
#The negative value which interprets that majority of the data are greater than the 
#mean which can also be interpreted that most data are concetrated on the right side of the tail.
advert_sk3
#Printing results for daily internet usage
#Daily internet usage column has a value close to 0 meaning its data is normally distributed.
advert_sk4
```

**Kurtosis**
``` {r}
#Finding the skewness in each cloumn
advert_kr1 <- kurtosis(advert$`Daily Time Spent on Site`)
advert_kr2 <- kurtosis(advert$Age)
advert_kr3 <- kurtosis(advert$`Area Income`)
advert_kr4 <- kurtosis(advert$`Daily Internet Usage`)
#Printing out the results for daily time spent on site
advert_kr1
#Printing results for Age
advert_kr2
#Printing the results for Area income
advert_kr3
#Printing results for daily internet usage
advert_kr4
#All the kurtosis values are less than 3 which is called Platykurtic.
```
```{r fig.height=3, fig.width=6}
library (tidyr)
advert %>%
  gather(attributes, value, 1:4) %>%
  ggplot(aes(x = value)) +
  geom_histogram(fill = 'lightblue2', color = 'black') +
  facet_wrap(~attributes, scales = 'free_x') +
  labs(x="Values", y="Frequency") +
  theme_bw()
```

1. Area Income is left skewed with the bracket between 60000 to 80000 having a high number of visitors to the site
2. Age is left skewed with the age bracket with a higher number of visitors is 30-31


**Categorical Values**

**Ad Topic Line**
```{r}
#Unique values in the column

uniq_topic <- unique(advert$`Ad Topic Line`, )
length(uniq_topic)
```
There are 1000 unique topic lines meaning it would be impossible to get a good visualization. 

**City** 
```{r}
#Unique values in the column

uniq_city <- unique(advert$City, )
length(uniq_city)
```
There are 969 unique cities hence it would also be impossible to get a good visualization

**Country**
```{r}
#Unique values in the column
uniq_country <- unique(advert$Country)
length(uniq_country)
```
There are 237 unique countries. 

**Gender**
```{r}
### Gender
ggplot(advert, aes(x = factor(Male))) +
  geom_bar(fill="steelblue") +  ggtitle('Count of Gender')
# male <- advert$Male
# male_freq <- table(male)
# barplot(male_freq, main= 'Gender Distribution', xlab="Gender",
# ylab="Number of people",
# col="steelblue")
```
Slightly more females than male(0 is female)

**Clicked on Ad**
```{r}
# Countplot for clicked on ad column
# This is to see the number of people that clicked on the ad 

ggplot(advert, aes(x = factor(`Clicked on Ad`))) +
  geom_bar(fill="steelblue") +  ggtitle('Count of Clicked on Ad')
```
There are equal values of clicked and not clicked on ad


**### Bivariate analysis** 


```{r}
#Area income vs clicked on ad
ggplot(data = advert, mapping = aes(x = `Area Income`)) + 
  geom_freqpoly(mapping = aes(colour = `Clicked on Ad`), binwidth = 2000)
```
As income increases, the rate of clicking on the Ad also increases

**Gender vs Clicked on Ad**
```{r}
# How the genders click on the Ad
ggplot(advert, aes(x = factor(Male), fill = factor(`Clicked on Ad`))) +
  geom_bar() +  ggtitle('Gender vs Clicked on Ad')
```
From the data, We have slightly more women than men visiting the site and more women clicking on the Ad.

**Age vs Daily Time Spent on Site**
```{r}
# Which Age group visits the site regularly
ggplot(advert, aes(x = `Daily Time Spent on Site`, y = Age, col = factor(`Clicked on Ad`))) +
  geom_point() +  ggtitle('Age vs Daily Time Spent on Site')
```
Visitors to the site who spent less time on the site were likely to click on the Ad

**Area Income vs Daily Time Spent on Site**
```{r}
# How the area income relates to the daily time spent on site
ggplot(advert, aes(x = `Daily Time Spent on Site`, y = `Area Income`, col = factor(`Clicked on Ad`))) +
  geom_point() +  ggtitle('Area Income vs Daily Time Spent on Site')
```
People who live in high income areas and spend more time on the sight are highly unlikely to click on the Ad

**Daily Internet Usage  vs Daily Time Spent on Site**
```{r}
ggplot(advert, aes(x = `Daily Time Spent on Site`, y = `Daily Internet Usage`, col = factor(`Clicked on Ad`))) +
  geom_point() +  ggtitle('Daily Internet Usage  vs Daily Time Spent on Site')
```
People whose daily internet usage is less and also the daily time spent on site is less are highly likey to click on the Ad

**Correlation**

``` {r}
#Finding the correlation of the numerical columns
# Identify numeric columns
library("dplyr") 
# Subset numeric columns with dplyr
data_num3 <- select_if(advert, is.numeric)             
data_num3 
# computing correlation matrix
library(corrplot)
#Assigning m to the correlation
# correlation matrix
M<-cor(data_num2)
corrplot(M, method="number")
```
From the correlation plot
1.  There is a moderate positive correlation of 0.52 between Daily internet usage and Daily time spent on site.

2.  There is also a weak positive correlation of 0.31 between area income and daily time spent on site

3.  There is a high negative correlation of -0.75 between clicked on ad and daily time spent on site

4.  There is a high negative correlation of -0.79 between clicked on ad and daily internet usage


## Conclusion

Below are some of the conclusions we have:

1.  Most of the individuals in the site are of the average age of 36.
2.   Individuals between the age of 30 - 50 spend the most time on the
    site.
3.  Individuals at the age of 31 are the most in the site.

## Recommendations

Our recommendations are:

1.   More advertisement should cater to individuals in their 30s but
    extend to the age bracket (30-50).





